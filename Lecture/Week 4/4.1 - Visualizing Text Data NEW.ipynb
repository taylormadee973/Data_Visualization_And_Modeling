{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualizing Text Data\n",
    "\n",
    "What makes text data so difficult to visualize?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unstructured nature of text data makes it much more difficult to analyze.  Because it often takes a lot of preprocessing to visualize text data, we'll focus on talking through these examples rather than writing code.\n",
    "\n",
    "In this lecture, we're going to focus on analyzing reviews of a few fancy European restaurants.  What do people like?  What are they complaing about?  How can we figure that out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some relationships we might try to visualize using this data?\n",
    "\n",
    "### We can use a word clouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
    "\n",
    "# Define additional stopwords to remove\n",
    "additional_stopwords = {'food', 'restaurant', 'good', 'best', 'great', 'bad', 'disappointing', 'dinner', 'place', 'excellent', 'amazing'}\n",
    "\n",
    "# Separate positive and negative reviews\n",
    "positive_reviews = ' '.join(df[df['Sentiment'] == 'Positive']['Review Title'].astype(str))\n",
    "negative_reviews = ' '.join(df[df['Sentiment'] == 'Negative']['Review Title'].astype(str))\n",
    "\n",
    "# Tokenize the words\n",
    "postive_words = positive_reviews.lower().split()\n",
    "    \n",
    "# Remove punctuation and stopwords (including additional stopwords)\n",
    "postive_words = [word.strip(string.punctuation) for word in postive_words if word.isalnum() and word not in sklearn_stop_words and word not in additional_stopwords]\n",
    "    \n",
    "# Generate the word cloud\n",
    "print('Positive Review Titles')\n",
    "wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(' '.join(postive_words))\n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#Negative reviews\n",
    "negative_words = negative_reviews.lower().split()\n",
    "    \n",
    "# Remove punctuation and stopwords (including additional stopwords)\n",
    "negative_words = [word.strip(string.punctuation) for word in negative_words if word.isalnum() and word not in sklearn_stop_words and word not in additional_stopwords]\n",
    "    \n",
    "# Generate the word cloud\n",
    "print('Negative Review Titles')\n",
    "wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(' '.join(negative_words))\n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some positive aspects of word clouds?  What are some negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can look at word frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_word_freq = Counter(postive_words)\n",
    "positive_common_words = positive_word_freq.most_common(20)\n",
    "    \n",
    "# Convert to DataFrame for plotting\n",
    "positive_freq_df = pd.DataFrame(positive_common_words, columns=['Word', 'Frequency'])\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(positive_freq_df['Word'], positive_freq_df['Frequency'])\n",
    "ax.set_title(f'Top 20 Words in Positive Review Titles')\n",
    "ax.set_xlabel('Word')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_word_freq = Counter(negative_words)\n",
    "negative_common_words = negative_word_freq.most_common(20)\n",
    "    \n",
    "# Convert to DataFrame for plotting\n",
    "negative_freq_df = pd.DataFrame(negative_common_words, columns=['Word', 'Frequency'])\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(negative_freq_df['Word'], negative_freq_df['Frequency'])\n",
    "ax.set_title(f'Top 20 Words in Negative Review Titles')\n",
    "ax.set_xlabel('Word')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n",
    "\n",
    "Another way to look at the data is to see how different words factor into the overall sentiment of a review.  There are different ways to do this, but one way is by using the textblob library (Python has tons of NLP libraries) to compute the sentiment of each review.  Sentiment can be positive (a positive value), negative (a negative value) or neutral (a value at or near 0).  \n",
    "\n",
    "Interestingly, the sentiment calculated by textblob doesn't align perfectly (though it does generally match up) with the positive/negative label given in the data.  \n",
    "\n",
    "Let's look at the sentiment vs subjectivity color coded by the sentiment label in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install textblob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from textblob import TextBlob\n",
    "import plotly.express as px\n",
    "\n",
    "# Sentiment calculations\n",
    "df['calc_sentiment'] = df['Review Title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['subjectivity'] = df['Review Title'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "df['abs_sentiment'] = df['calc_sentiment'].abs()\n",
    "\n",
    "# Optional: Make sentiment a category to suppress warning\n",
    "df['Sentiment'] = df['Sentiment'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "# scatter plot of sentiment polarity vs subjectivity\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='calc_sentiment',\n",
    "    y='subjectivity',\n",
    "    color='Sentiment',\n",
    "    size='abs_sentiment',\n",
    "    size_max=15,\n",
    "    hover_name='Restaurant Name',\n",
    "    hover_data={'Review Title': True},\n",
    "    labels={\n",
    "        'calc_sentiment': 'Sentiment Polarity',\n",
    "        'subjectivity': 'Subjectivity'\n",
    "    },\n",
    "    title='Sentiment Polarity vs Subjectivity'\n",
    ")\n",
    "\n",
    "# adjust axis titles and overall height\n",
    "fig.update_layout(\n",
    "    xaxis_title='Sentiment Polarity',\n",
    "    yaxis_title='Subjectivity',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets color code by restaruant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x='calc_sentiment', y='subjectivity', \n",
    "                 hover_data=['Review Title'],\n",
    "                 color='Restaurant Name',\n",
    "                 size='abs_sentiment',\n",
    "                 size_max = 15,\n",
    "                 title='Sentiment Polarity vs Subjectivity',\n",
    "                 hover_name = 'Restaurant Name',\n",
    "                 labels={'sentiment': 'Sentiment Polarity', 'subjectivity': 'Subjectivity'})\n",
    "\n",
    "fig.update_layout(xaxis_title = 'Sentiment', height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the range of sentiment associated with each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "keywords = [\"wait\", \"service\", \"expensive\"] #[\"disgusting\", \"delicious\", \"overpriced\"]  ##, ['lunch']]\n",
    "\n",
    "# Filter reviews based on the presence of keywords and compute sentiment for each keyword\n",
    "sentiments = {}\n",
    "for keyword in keywords:\n",
    "    sentiments[keyword] = df[df['Review'].str.contains(keyword, case=False, na=False)]['calc_sentiment']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "for keyword, sentiment in sentiments.items():\n",
    "    sns.histplot(sentiment, label=keyword)\n",
    "    \n",
    "plt.title('Sentiment Distribution by Keyword')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cosine Similarity\n",
    " \n",
    "Turn each text into a vector of word counts. \n",
    "Then measure how close the two vectors point using the cosine of the angle between them.\n",
    "\n",
    "$\\displaystyle \\mathrm{cosine\\_sim}(A,B) = \\frac{A \\cdot B}{\\lVert A\\rVert\\,\\lVert B\\rVert}$\n",
    "\n",
    "\n",
    "- $A \\cdot B$: dot product (sum of element‑wise products)  \n",
    "- $\\lVert A\\rVert$: Euclidean norm (length) of vector $A$  \n",
    "- $\\lVert B\\rVert$: Euclidean norm (length) of vector $B$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visual Intuition\n",
    "\n",
    "      ^ \n",
    "      |        B\n",
    "      |       /\n",
    "      |      /\n",
    "      |     / ) θ\n",
    "      |    / \n",
    "      |   /\n",
    "      |  / A\n",
    "      +----------------->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- If θ = 0° (vectors point the same way), cosine similarity = 1  \n",
    "- If θ = 90° (orthogonal), cosine similarity = 0  \n",
    "- If θ = 180° (opposite), cosine similarity = –1 (rare in bag‑of‑words)\n",
    "\n",
    "---\n",
    "\n",
    "### Mini Text Example\n",
    "\n",
    "Two short “documents”:\n",
    "\n",
    "- **T1:** “the cat sat on the mat”  \n",
    "- **T2:** “the dog lay on the rug”\n",
    "\n",
    "**Step 1 – Vocabulary:**  \n",
    "`[the, on, cat, sat, mat, dog, lay, rug]`\n",
    "\n",
    "**Step 2 – Count vectors:**  \n",
    "\n",
    "| Word | T1 | T2 |\n",
    "|------|----|----|\n",
    "| the  |  2 |  2 |\n",
    "| on   |  1 |  1 |\n",
    "| cat  |  1 |  0 |\n",
    "| sat  |  1 |  0 |\n",
    "| mat  |  1 |  0 |\n",
    "| dog  |  0 |  1 |\n",
    "| lay  |  0 |  1 |\n",
    "| rug  |  0 |  1 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dot product:**  \n",
    "\n",
    "| Word | T1 | T2 | Product (T1 × T2) |\n",
    "| ---- | -- | -- | ----------------- |\n",
    "| the  | 2  | 2  | 4                 |\n",
    "| on   | 1  | 1  | 1                 |\n",
    "| cat  | 1  | 0  | 0                 |\n",
    "| sat  | 1  | 0  | 0                 |\n",
    "| mat  | 1  | 0  | 0                 |\n",
    "| dog  | 0  | 1  | 0                 |\n",
    "| lay  | 0  | 1  | 0                 |\n",
    "| rug  | 0  | 1  | 0                 |\n",
    "| total|    |    | 5                 |     \n",
    "\n",
    "\n",
    "- **Vector norms:**  \n",
    "  $$\n",
    "    \\lVert T_1 \\rVert\n",
    "    = \\sqrt{2^2 + 1^2 + 1^2 + 1^2 + 1^2}\n",
    "    = \\sqrt{8}\n",
    "  $$\n",
    "  $$\n",
    "    \\lVert T_2 \\rVert\n",
    "    = \\sqrt{2^2 + 1^2 + 1^2 + 1^2 + 1^2}\n",
    "    = \\sqrt{8}\n",
    "  $$\n",
    "\n",
    "- **Cosine similarity:**  \n",
    "  $$\n",
    "    \\operatorname{cosine\\_sim}(T_1, T_2)\n",
    "    = \\frac{T_1 \\cdot T_2}{\\lVert T_1 \\rVert \\;\\lVert T_2 \\rVert}\n",
    "    = \\frac{5}{\\sqrt{8}\\;\\sqrt{8}}\n",
    "    = \\frac{5}{8}\n",
    "    = 0.625\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Updated sentences with more overlap\n",
    "sentences = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog sat on the mat next to the cat.\",\n",
    "    \"Quantum physics explores the behavior of subatomic particles.\",\n",
    "    \"I love exploring particle behavior when eating sushi with friends.\"\n",
    "]\n",
    "\n",
    "# Tokenize and count words using regex (avoids extra NLTK/TextBlob dependencies)\n",
    "def wc_vector(text, vocab):\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "    wc = Counter(tokens)\n",
    "    return np.array([wc.get(word, 0) for word in vocab])\n",
    "\n",
    "# Build a sorted global vocabulary\n",
    "vocab = set()\n",
    "for s in sentences:\n",
    "    vocab.update(re.findall(r\"\\b\\w+\\b\", s.lower()))\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Compute word‑count vectors for each sentence\n",
    "vectors = [wc_vector(s, vocab) for s in sentences]\n",
    "\n",
    "# Cosine‐similarity function\n",
    "def cosine_sim(a, b):\n",
    "    dot = np.dot(a, b)\n",
    "    na = np.linalg.norm(a)\n",
    "    nb = np.linalg.norm(b)\n",
    "    return dot / (na * nb) if na and nb else 0.0\n",
    "\n",
    "# Build the full pairwise similarity matrix\n",
    "N = len(vectors)\n",
    "sim_matrix = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        sim_matrix[i, j] = cosine_sim(vectors[i], vectors[j])\n",
    "\n",
    "# Plotting the similarity matrix as a heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(sim_matrix, interpolation='nearest')\n",
    "plt.colorbar(label='Cosine Similarity')\n",
    "\n",
    "labels = [f\"Sentence {i+1}\" for i in range(N)]\n",
    "plt.xticks(range(N), labels, rotation=45)\n",
    "plt.yticks(range(N), labels)\n",
    "\n",
    "plt.title(\"Pairwise Cosine Similarity\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
